@inproceedings{dziedzic2014analysis,
    title = {Analysis and comparison of NoSQL databases with an introduction to consistent references in Big Data storage systems},
    author = {Dziedzic, Adam and Mulawka, Jan},
    booktitle = {Photonics Applications in Astronomy, Communications, Industry, and High-Energy Physics Experiments},
    volume = {9290},
    pages = {92902V},
    year = {2014},
    organization = {International Society for Optics and Photonics},
    abstract = {NoSQL is a new approach to data storage and manipulation. The aim of this paper is to gain more insight into NoSQL databases, as we are still in the early stages of understanding when to use them and how to use them in an appropriate way. In this submission descriptions of selected NoSQL databases are presented. Each of the databases is analysed with primary focus on its data model, data access, architecture and practical usage in real applications. Furthemore, the NoSQL databases are compared in fields of data references. The relational databases offer foreign keys, whereas NoSQL databases provide us with limited references. An intermediate model between graph theory and relational algebra which can address the problem should be created. Finally, the proposal of a new approach to the problem of inconsistent references in Big Data storage systems is introduced.},
    url = {https://adam-dziedzic.com/static/assets/papers/nosql.pdf},
}

@inproceedings{meehan2016integrating,
    title = {Integrating Real-Time and Batch Processing in a Polystore},
    author = {Meehan, John and Zdonik, Stan and Tian, Shaobo and Tian, Yulong and Tatbul, Nesime and Dziedzic, Adam and Elmore, Aaron},
    booktitle = {HPEC (IEEE High Performance Extreme Computing)},
    year = {2016},
    abstract = {This paper describes a stream processing engine called S-Store and its role in the BigDAWG polystore. Fundamentally, S-Store acts as a frontend processor that accepts input from multiple sources, and massages it into a form that has eliminated errors (data cleaning) and translates that input into a form that can be efficiently ingested into BigDAWG. S-Store also acts as an intelligent router that sends input tuples to the appropriate components of BigDAWG. All updates to S-Store's shared memory are done in a transactionally consistent (ACID) way, thereby eliminating new errors caused by non-synchronized reads and writes. The ability to migrate data from component to component of BigDAWG is crucial. We have described a migrator from S-Store to Postgres that we have implemented as a first proof of concept. We report some interesting results using this migrator that impact the evaluation of query plans.},
    url = {https://adam-dziedzic.com/static/assets/papers/dziedzic-s-store-hpec.pdf},
}

@article{obrien2017bigdawg,
    title = {Bigdawg polystore release and demonstration},
    author = {OBrien, Kyle and Gadepally, Vijay and Duggan, Jennie and Dziedzic, Adam and Elmore, Aaron and Kepner, Jeremy and Madden, Samuel and Mattson, Tim and She, Zuohao and Stonebraker, Michael},
    journal = {preprint arXiv:1701.05799},
    year = {2017}
}

@article{gadepally2017version,
    title = {Version 0.1 of the bigdawg polystore system},
    author = {Gadepally, Vijay and OBrien, Kyle and Dziedzic, Adam and Elmore, Aaron and Kepner, Jeremy and Madden, Samuel and Mattson, Tim and Rogers, Jennie and She, Zuohao and Stonebraker, Michael},
    journal = {preprint arXiv:1707.00721},
    year = {2017}
}

@inproceedings{gadepally2017bigdawg,
    title = {BigDAWG version 0.1},
    author = {Gadepally, Vijay and O'Brien, Kyle and Dziedzic, Adam and Elmore, Aaron and Kepner, Jeremy and Madden, Samuel and Mattson, Tim and Rogers, Jennie and She, Zuohao and Stonebraker, Michael},
    booktitle = {HPEC (IEEE High Performance Extreme Computing)},
    pages = {1--7},
    year = {2017},
    organization = {IEEE}
}

@article{dziedzic2017data,
    title = {Data Loading, Transformation and Migration for Database Management Systems},
    author = {Dziedzic, Adam},
    year = {2017},
    publisher = {The University of Chicago},
    pub_type = {Thesis},
    url = {https://newtraell.cs.uchicago.edu/files/ms_paper/ady.pdf},
}

@article{gadepallyseptember,
    title = {September 2017. BigDAWG Version 0.1},
    author = {Gadepally, V and O'Brien, K and Dziedzic, A and Elmore, A and Kepner, J and Madden, S and Mattson, T and Rogers, J and She, Z and Stonebraker, M},
    journal = {HPEC (IEEE High Performance Extreme Computing)},
    year = {2017},
}

@article{krishnan2018deeplens,
    title = {Deeplens: Towards a visual data management system},
    author = {Krishnan, Sanjay and Dziedzic, Adam and Elmore, Aaron J},
    journal = {CIDR (Conference on Innovative Data Systems Research)},
    year = {2018},
    url = {https://adam-dziedzic.com/static/assets/papers/deeplens.pdf},
    abstract = {Advances in deep learning have greatly widened the scope of automatic computer vision algorithms and enable users to ask questions directly about the content in images and video. This paper explores the necessary steps towards a future Visual Data Management System (VDMS), where the predictions of such deep learning models are stored, managed, queried, and indexed. We propose a query and data model that disentangles the neural network models used, the query workload, and the data source semantics from the query processing layer. Our system, DeepLens, is based on dataflow query processing systems and this research prototype presents initial experiments to elicit important open research questions in visual analytics systems. One of our main conclusions is that any future "declarative" VDMS will have to revisit query optimization and automated physical design from a unified perspective of performance and accuracy tradeoffs. Physical design and query optimization choices can not only change performance by orders of magnitude, they can potentially affect the accuracy of results.},
}

@article{krishnan2019artificial,
    title = {Artificial intelligence in resource-constrained and shared environments},
    author = {Krishnan, Sanjay and Elmore, Aaron J and Franklin, Michael and Paparrizos, John and Shang, Zechao and Dziedzic, Adam and Liu, Rui},
    journal = {ACM SIGOPS Operating Systems Review},
    volume = {53},
    number = {1},
    pages = {1--6},
    year = {2019},
    publisher = {ACM New York, NY, USA},
    url = {https://dl.acm.org/doi/abs/10.1145/3352020.3352022},
    abstract = {The computational demands of modern AI techniques are immense, and as the number of practical applications grows, there will be an increasing burden on shared computing infrastructure. We envision a forthcoming era of "AI Systems" research where reducing resource consumption, reasoning about transient resource availability, trading off resource consumption for accuracy, and managing contention on specialized hardware will become the community's main research focus. This paper overviews the history of AI systems research, a vision for the future, and the open challenges ahead.},
}

@inproceedings{sathya2020machine,
    title = {Machine Learning based detection of multiple Wi-Fi BSSs for LTE-U CSAT},
    author = {Sathya, Vanlin and Dziedzic, Adam and Ghosh, Monisha and Krishnan, Sanjay},
    booktitle = {ICNC (International Conference on Computing, Networking and Communications)},
    year = {2020},
    organization = {IEEE},
    abstract = {According to the LTE-U Forum specification, a LTE-U base-station (BS) reduces its duty cycle from 50% to 33% when it senses an increase in the number of co-channel Wi-Fi basic service sets (BSSs) from one to two. The detection of the number of Wi-Fi BSSs that are operating on the channel in real-time, without decoding the Wi-Fi packets, still remains a challenge. In this paper, we present a novel machine learning (ML) approach that solves the problem by using energy values observed during LTE-U OFF duration. Observing the energy values (at LTE-U BS OFF time) is a much simpler operation than decoding the entire Wi-Fi packets. In this work, we implement and validate the proposed ML based approach in real-time experiments, and demonstrate that there are two distinct patterns between one and two Wi-Fi APs. This approach delivers an accuracy close to 100% compared to auto-correlation (AC) and energy detection (ED) approaches.},
    url = {https://adam-dziedzic.com/static/assets/papers/Machine_Learning_based_detection_of_multiple_Wi-Fi.pdf},
}

@article{dziedzic2020empirical,
    title = {An Empirical Evaluation of Perturbation-based Defenses},
    author = {Dziedzic, Adam and Krishnan, Sanjay},
    journal = {preprint arXiv:2002.03080},
    year = {2020},
    abstract = {Recent work has extensively shown that randomized perturbations of a neural network can improve its robustness to adversarial attacks. The literature is, however, lacking a detailed compare-and-contrast of the latest proposals to understand what classes of perturbations work, when they work, and why they work. We contribute a detailed experimental evaluation that elucidates these questions and benchmarks perturbation defenses in a consistent way. In particular, we show five main results: (1) all input perturbation defenses, whether random or deterministic, are essentially equivalent in their efficacy, (2) such defenses offer almost no robustness to adaptive attacks unless these perturbations are observed during training, (3) a tuned sequence of noise layers across a network provides the best empirical robustness, (4) attacks transfer between perturbation defenses so the attackers need not know the specific type of defense only that it involves perturbations, and (5) adversarial examples very close to original images show an elevated sensitivity to perturbation in a first-order analysis. Based on these insights, we demonstrate a new robust model built on noise injection and adversarial training that achieves state-of-the-art robustness.},
}

@article{dziedzic2020machine,
    title = {Machine Learning enabled Spectrum Sharing in Dense LTE-U/Wi-Fi Coexistence Scenarios},
    author = {Dziedzic, Adam and Sathya, Vanlin and Rochman, Muhammad and Ghosh, Monisha and Krishnan, Sanjay},
    journal = {OJVT (IEEE Open Journal of Vehicular Technology)},
    year = {2020},
    publisher = {IEEE},
    abstract = {The application of Machine Learning (ML) techniques to complex engineering problems has proved to be an attractive and efficient solution. ML has been successfully applied to several practical tasks like image recognition, automating industrial operations, etc. The promise of ML techniques in solving non-linear problems influenced this work which aims to apply known ML techniques and develop new ones for wireless spectrum sharing between Wi-Fi and LTE in the unlicensed spectrum. In this work, we focus on the LTE-Unlicensed (LTE-U) specification developed by the LTE-U Forum, which uses the duty-cycle approach for fair coexistence. The specification suggests reducing the duty cycle at the LTE-U base-station (BS) when the number of co-channel Wi-Fi basic service sets (BSSs) increases from one to two or more. However, without decoding the Wi-Fi packets, detecting the number of Wi-Fi BSSs operating on the channel in real-time is a challenging problem. In this work, we demonstrate a novel ML-based approach which solves this problem by using energy values observed during the LTE-U OFF duration. It is relatively straightforward to observe only the energy values during the LTE-U BS OFF time compared to decoding the entire Wi-Fi packet, which would require a full Wi-Fi receiver at the LTE-U base-station. We implement and validate the proposed ML-based approach by real-time experiments and demonstrate that there exist distinct patterns between the energy distributions between one and many Wi-Fi AP transmissions. The proposed ML-based approach results in a higher accuracy (close to 99% in all cases) as compared to the existing auto-correlation (AC) and energy detection (ED) approaches.}
}

@article{dziedzic2020input,
    title = {Input and Model Compression for Adaptive and Robust Neural Networks},
    author = {Dziedzic, Adam},
    year = {2020},
    publisher = {The University of Chicago},
    pub_type = {Thesis},
    url = {https://knowledge.uchicago.edu/record/2637?ln=en},
}

@article{wong2021ML,
    author = {Wong, Arnold Y. L. and Harada, Garrett and Lee, Remy and Gandhi, Sapan D. and Dziedzic, Adam and Espinoza-Orias, Alejandro and Parnianpour, Mohamad and Louie, Philip K. and Basques, Bryce and An, Howard S. and Samartzis, Dino},
    title = {Preoperative paraspinal neck muscle characteristics predict early onset adjacent segment degeneration in anterior cervical fusion patients: A machine-learning modeling analysis},
    journal = {Journal of Orthopaedic Research},
    volume = {39},
    number = {8},
    pages = {1732-1744},
    keywords = {adjacent segment, cervical, degeneration, disc, disease, muscles, paraspinal, spine},
    doi = {https://doi.org/10.1002/jor.24829},
    url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jor.24829},
    eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/jor.24829},
    abstract = {Abstract Early onset adjacent segment degeneration (ASD) can be found within six months after anterior cervical discectomy and fusion (ACDF). Deficits in deep paraspinal neck muscles may be related to early onset ASD. This study aimed to determine whether the morphometry of preoperative deep neck muscles (multifidus and semispinalis cervicis) predicted early onset ASD in patients with ACDF. Thirty-two cases of early onset ASD after a two-level ACDF and 30 matched non-ASD cases were identified from a large-scale cohort. The preoperative total cross-sectional area (CSA) of bilateral deep neck muscles and the lean muscle CSAs from C3 to C7 levels were measured manually on T2-weighted magnetic resonance imaging. Paraspinal muscle CSA asymmetry at each level was calculated. A support vector machine (SVM) algorithm was used to identify demographic, radiographic, and/or muscle parameters that predicted proximal/distal ASD development. No significant between-group differences in demographic or preoperative radiographic data were noted (mean age: 52.4 ± 10.9 years). ACDFs comprised C3 to C5 (n = 9), C4 to C6 (n = 20), and C5 to C7 (n = 32) cases. Eighteen, eight, and six patients had proximal, distal, or both ASD, respectively. The SVM model achieved high accuracy (96.7\%) and an area under the curve (AUC = 0.97) for predicting early onset ASD. Asymmetry of fat at C5 (coefficient: 0.06), and standardized measures of C7 lean (coefficient: 0.05) and total CSA measures (coefficient: 0.05) were the strongest predictors of early onset ASD. This is the first study to show that preoperative deep neck muscle CSA, composition, and asymmetry at C5 to C7 independently predicted postoperative early onset ASD in patients with ACDF. Paraspinal muscle assessments are recommended to identify high-risk patients for personalized intervention.},
    year = {2021}
}

@misc{travers2021exploitability,
    title = {On the Exploitability of Audio Machine Learning Pipelines to Surreptitious Adversarial Examples},
    author = {Adelin Travers and Lorna Licollari and Guanghan Wang and Varun Chandrasekaran and Adam Dziedzic and David Lie and Nicolas Papernot},
    year = {2021},
    eprint = {2108.02010},
    archivePrefix = {arXiv},
    primaryClass = {cs.SD},
    journal = {preprint arXiv:2108.02010},
    abstract = {Machine learning (ML) models are known to be vulnerable to adversarial examples. Applications of ML to voice biometrics authentication are no exception. Yet, the implications of audio adversarial examples on these real-world systems remain poorly understood given that most research targets limited defenders who can only listen to the audio samples. Conflating detectability of an attack with human perceptibility, research has focused on methods that aim to produce imperceptible adversarial examples which humans cannot distinguish from the corresponding benign samples. We argue that this perspective is coarse for two reasons: 1. Imperceptibility is impossible to verify; it would require an experimental process that encompasses variations in listener training, equipment, volume, ear sensitivity, types of background noise etc, and 2. It disregards pipeline-based detection clues that realistic defenders leverage. This results in adversarial examples that are ineffective in the presence of knowledgeable defenders. Thus, an adversary only needs an audio sample to be plausible to a human. We thus introduce surreptitious adversarial examples, a new class of attacks that evades both human and pipeline controls. In the white-box setting, we instantiate this class with a joint, multi-stage optimization attack. Using an Amazon Mechanical Turk user study, we show that this attack produces audio samples that are more surreptitious than previous attacks that aim solely for imperceptibility. Lastly we show that surreptitious adversarial examples are challenging to develop in the black-box setting.}
}

@misc{boenisch2021curious,
      title={When the Curious Abandon Honesty: Federated Learning Is Not Private},
      author={Franziska Boenisch and Adam Dziedzic and Roei Schuster and Ali Shahin Shamsabadi and Ilia Shumailov and Nicolas Papernot},
      year={2021},
      eprint={2112.02918},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      journal = {preprint arXiv:2112.02918},
      url = {https://arxiv.org/abs/2112.02918},
      abstract = {In federated learning (FL), data does not leave personal devices when they are jointly training a machine learning model. Instead, these devices share gradients with a central party (e.g., a company). Because data never "leaves" personal devices, FL is presented as privacy-preserving. Yet, recently it was shown that this protection is but a thin facade, as even a passive attacker observing gradients can reconstruct data of individual users. In this paper, we argue that prior work still largely underestimates the vulnerability of FL. This is because prior efforts exclusively consider passive attackers that are honest-but-curious. Instead, we introduce an active and dishonest attacker acting as the central party, who is able to modify the shared model's weights before users compute model gradients. We call the modified weights "trap weights". Our active attacker is able to recover user data perfectly and at near zero costs: the attack requires no complex optimization objectives. Instead, it exploits inherent data leakage from model gradients and amplifies this effect by maliciously altering the weights of the shared model. These specificities enable our attack to scale to models trained with large mini-batches of data. Where attackers from prior work require hours to recover a single data point, our method needs milliseconds to capture the full mini-batch of data from both fully-connected and convolutional deep neural networks. Finally, we consider mitigations. We observe that current implementations of differential privacy (DP) in FL are flawed, as they explicitly trust the central party with the crucial task of adding DP noise, and thus provide no protection against a malicious central party. We also consider other defenses and explain why they are similarly inadequate. A significant redesign of FL is required for it to provide any meaningful form of data privacy to users.},
}

@misc{IntelPrivateAIVision2021,
      title={Private AI Collaborative Research Institute: Vision, Challenges, and Opportunities},
      author={Ahmad-Reza Sadeghi and Ferdinand Brasser and Markus Miettinen and Thien Duc Nguyen and Thomas Given-Wilson and Axel Legay and Murali Annaaram and Salman Avestimeh and Alexandra Dmitrienko and Farinaz Koushanfar and Buse Gul Atli and Florian Kerschbaum and Lachlan J. Gunn and N. Asokan and Matthias Schunter and Rosario Cammarota and Adam Dziedzic and Nicolas Papernot and Virginia Smith and Reza Shokri} and
      year={2021},
      url = {https://www.private-ai.org/blog/wp-content/uploads/2021/11/Visionpaper_final_single-pages.pdf},
      abstract = {This document outlines the research vision of the collaborative research center for Privacy-preserving Machine Learning. While federated machine learning starts to be deployed, its security and privacy implications are not well understood today. Our goal is to conduct research enabling the future of decentralized machine learning: Underpinning Federated ML with robust privacy guarantees and efficient algoritms to achieve those guarantees. Exploring knowledge transfer and collaborative ML beyond Federated machine learning that suffers from a central controller as its root of trust.  Exploring Graph Neural Networks and their privacy implications. Ensuring robustness against malicious participants that may steal models or may try to poison maching learning models during training. This research will then be validated in case studies and deployed in open source frameworks to allow further experimentation and deployment on a wider scale.},
}

