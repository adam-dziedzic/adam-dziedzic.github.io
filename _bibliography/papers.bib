@inproceedings{dziedzic2014analysis,
    title = {Analysis and comparison of NoSQL databases with an introduction to consistent references in Big Data storage systems},
    author = {Dziedzic, Adam and Mulawka, Jan},
    booktitle = {Photonics Applications in Astronomy, Communications, Industry, and High-Energy Physics Experiments 2014},
    volume = {9290},
    pages = {92902V},
    year = {2014},
    organization = {International Society for Optics and Photonics}
}

@inproceedings{dziedzic2015bigdawg,
    title = {BigDAWG: a Polystore for Diverse Interactive Applications},
    author = {Dziedzic, Adam and Duggan, Jennie and Elmore, Aaron J. and Gadepally, Vijay and Stonebraker, Michael},
    booktitle = {IEEE Viz Data Systems for Interactive Analysis (DSIA)},
    year = {2015}
}

@inproceedings{meehan2016integrating,
    title = {Integrating Real-Time and Batch Processing in a Polystore},
    author = {Meehan, John and Zdonik, Stan and Tian, Shaobo and Tian, Yulong and Tatbul, Nesime and Dziedzic, Adam and Elmore, Aaron},
    booktitle = {HPEC 2016},
    year = {2016}
}

@inproceedings{dziedzic2016data,
    title = {Data Transformation and Migration in Polystores},
    author = {Dziedzic, Adam and Elmore, Aaron and Stonebraker, Michael},
    booktitle = {HPEC 2016},
    year = {2016},
    organization = {IEEE}
}

@inproceedings{dziedzic2016dbms,
    title = {DBMS Data Loading: An Analysis on Modern Hardware},
    author = {Dziedzic, Adam and Karpathiotakis, Manos and Alagiannis, Ioannis and Appuswamy, Raja and Ailamaki, Anastasia},
    booktitle = {ADMS 2016},
    year = {2016}
}

@inproceedings{mattson2017demonstrating,
    title = {Demonstrating the BigDAWG Polystore System for Ocean Metagenomics Analysis.},
    author = {Mattson, Tim and Gadepally, Vijay and She, Zuohao and Dziedzic, Adam and Parkhurst, Jeff},
    booktitle = {CIDR},
    year = {2017}
}

@article{obrien2017bigdawg,
    title = {Bigdawg polystore release and demonstration},
    author = {OBrien, Kyle and Gadepally, Vijay and Duggan, Jennie and Dziedzic, Adam and Elmore, Aaron and Kepner, Jeremy and Madden, Samuel and Mattson, Tim and She, Zuohao and Stonebraker, Michael},
    journal = {arXiv preprint arXiv:1701.05799},
    year = {2017}
}

@article{gadepally2017version,
    title = {Version 0.1 of the bigdawg polystore system},
    author = {Gadepally, Vijay and OBrien, Kyle and Dziedzic, Adam and Elmore, Aaron and Kepner, Jeremy and Madden, Samuel and Mattson, Tim and Rogers, Jennie and She, Zuohao and Stonebraker, Michael},
    journal = {arXiv preprint arXiv:1707.00721},
    year = {2017}
}

@inproceedings{gadepally2017bigdawg,
    title = {BigDAWG version 0.1},
    author = {Gadepally, Vijay and O'Brien, Kyle and Dziedzic, Adam and Elmore, Aaron and Kepner, Jeremy and Madden, Samuel and Mattson, Tim and Rogers, Jennie and She, Zuohao and Stonebraker, Michael},
    booktitle = {2017 IEEE High Performance Extreme Computing Conference (HPEC)},
    pages = {1--7},
    year = {2017},
    organization = {IEEE}
}

@inproceedings{dziedzic2018columnstore,
    title = {Columnstore and B+ tree-Are Hybrid Physical Designs Important?},
    author = {Dziedzic, Adam and Wang, Jingjing and Das, Sudipto and Ding, Bolin and Narasayya, Vivek R and Syamala, Manoj},
    booktitle = {Proceedings of the 2018 International Conference on Management of Data (SIGMOD 2018)},
    pages = {177--190},
    year = {2018},
    organization = {ACM}
}

@article{krishnan2018deeplens,
    title = {Deeplens: Towards a visual data management system},
    author = {Krishnan, Sanjay and Dziedzic, Adam and Elmore, Aaron J},
    journal = {CIDR},
    year = {2018}
}

@inproceedings{dziedzic2019band,
    title = {Band-limited Training and Inference for Convolutional Neural Networks},
    author = {Dziedzic, Adam and Paparizzos, Ioannis and Krishnan, Sanjay and Elmore, Aaron and Franklin, Michael},
    booktitle = {ICML (International Conference on Machine Learning)},
    year = {2019}
}

@article{krishnan2019artificial,
    title = {Artificial intelligence in resource-constrained and shared environments},
    author = {Krishnan, Sanjay and Elmore, Aaron J and Franklin, Michael and Paparrizos, John and Shang, Zechao and Dziedzic, Adam and Liu, Rui},
    journal = {ACM SIGOPS Operating Systems Review},
    volume = {53},
    number = {1},
    pages = {1--6},
    year = {2019},
    publisher = {ACM New York, NY, USA}
}

@phdthesis{dziedzic2017data,
    title = {Data Loading, Transformation and Migration for Database Management Systems},
    author = {Dziedzic, Adam},
    year = {2017},
    school = {The University of Chicago}
}

@inproceedings{sathya2020machine,
    title = {Machine Learning based detection of multiple Wi-Fi BSSs for LTE-U CSAT},
    author = {Sathya, Vanlin and Dziedzic, Adam and Ghosh, Monisha and Krishnan, Sanjay},
    booktitle = {International Conference on Computing, Networking and Communications (ICNC 2020)},
    year = {2020},
    organization = {IEEE}
}

@article{gadepallyseptember,
    title = {September 2017. BigDAWG Version 0.1},
    author = {Gadepally, V and O'Brien, K and Dziedzic, A and Elmore, A and Kepner, J and Madden, S and Mattson, T and Rogers, J and She, Z and Stonebraker, M},
    journal = {IEEE High Performance Extreme}
}

@article{dziedzic2020empirical,
    title = {An Empirical Evaluation of Perturbation-based Defenses},
    author = {Dziedzic, Adam and Krishnan, Sanjay},
    journal = {arXiv preprint arXiv:2002.03080},
    year = {2020}
}

@article{dziedzic2020machine,
    title = {Machine Learning enabled Spectrum Sharing in Dense LTE-U/Wi-Fi Coexistence Scenarios},
    author = {Dziedzic, Adam and Sathya, Vanlin and Rochman, Muhammad and Ghosh, Monisha and Krishnan, Sanjay},
    journal = {IEEE Open Journal of Vehicular Technology},
    year = {2020},
    publisher = {IEEE}
}

@article{dziedzic2019perturbation,
    title = {A Perturbation Analysis of Input Transformations for Adversarial Attacks},
    author = {Dziedzic, Adam and Krishnan, Sanjay},
    year = {2019}
}

@article{dziedzic2020input,
    title = {Input and Model Compression for Adaptive and Robust Neural Networks},
    author = {Dziedzic, Adam},
    year = {2020},
    publisher = {The University of Chicago}
}

@inproceedings{
capc2021iclr,
    title = {CaPC Learning: Confidential and Private Collaborative Learning},
    author = {Christopher A. Choquette-Choo and Natalie Dullerud and Adam Dziedzic and Yunxiang Zhang and Somesh Jha and Nicolas Papernot and Xiao Wang},
    booktitle = {International Conference on Learning Representations},
    year = {2021},
    url = {https://openreview.net/forum?id=h2EbJ4_wMVq}
}

@inproceedings{hendrycks-etal-2020-pretrained,
    title = "Pretrained Transformers Improve Out-of-Distribution Robustness",
    author = "Hendrycks, Dan  and
      Liu, Xiaoyuan  and
      Wallace, Eric  and
      Dziedzic, Adam  and
      Krishnan, Rishabh  and
      Song, Dawn",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.244",
    doi = "10.18653/v1/2020.acl-main.244",
    pages = "2744--2751",
    abstract = "Although pretrained Transformers such as BERT achieve high accuracy on in-distribution examples, do they generalize to new distributions? We systematically measure out-of-distribution (OOD) generalization for seven NLP datasets by constructing a new robustness benchmark with realistic distribution shifts. We measure the generalization of previous models including bag-of-words models, ConvNets, and LSTMs, and we show that pretrained Transformers{'} performance declines are substantially smaller. Pretrained transformers are also more effective at detecting anomalous or OOD examples, while many previous models are frequently worse than chance. We examine which factors affect robustness, finding that larger models are not necessarily more robust, distillation can be harmful, and more diverse pretraining data can enhance robustness. Finally, we show where future work can improve OOD robustness.",
}

@article{wong2021ML,
    author = {Wong, Arnold Y. L. and Harada, Garrett and Lee, Remy and Gandhi, Sapan D. and Dziedzic, Adam and Espinoza-Orias, Alejandro and Parnianpour, Mohamad and Louie, Philip K. and Basques, Bryce and An, Howard S. and Samartzis, Dino},
    title = {Preoperative paraspinal neck muscle characteristics predict early onset adjacent segment degeneration in anterior cervical fusion patients: A machine-learning modeling analysis},
    journal = {Journal of Orthopaedic Research},
    volume = {39},
    number = {8},
    pages = {1732-1744},
    keywords = {adjacent segment, cervical, degeneration, disc, disease, muscles, paraspinal, spine},
    doi = {https://doi.org/10.1002/jor.24829},
    url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jor.24829},
    eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/jor.24829},
    abstract = {Abstract Early onset adjacent segment degeneration (ASD) can be found within six months after anterior cervical discectomy and fusion (ACDF). Deficits in deep paraspinal neck muscles may be related to early onset ASD. This study aimed to determine whether the morphometry of preoperative deep neck muscles (multifidus and semispinalis cervicis) predicted early onset ASD in patients with ACDF. Thirty-two cases of early onset ASD after a two-level ACDF and 30 matched non-ASD cases were identified from a large-scale cohort. The preoperative total cross-sectional area (CSA) of bilateral deep neck muscles and the lean muscle CSAs from C3 to C7 levels were measured manually on T2-weighted magnetic resonance imaging. Paraspinal muscle CSA asymmetry at each level was calculated. A support vector machine (SVM) algorithm was used to identify demographic, radiographic, and/or muscle parameters that predicted proximal/distal ASD development. No significant between-group differences in demographic or preoperative radiographic data were noted (mean age: 52.4 ± 10.9 years). ACDFs comprised C3 to C5 (n = 9), C4 to C6 (n = 20), and C5 to C7 (n = 32) cases. Eighteen, eight, and six patients had proximal, distal, or both ASD, respectively. The SVM model achieved high accuracy (96.7\%) and an area under the curve (AUC = 0.97) for predicting early onset ASD. Asymmetry of fat at C5 (coefficient: 0.06), and standardized measures of C7 lean (coefficient: 0.05) and total CSA measures (coefficient: 0.05) were the strongest predictors of early onset ASD. This is the first study to show that preoperative deep neck muscle CSA, composition, and asymmetry at C5 to C7 independently predicted postoperative early onset ASD in patients with ACDF. Paraspinal muscle assessments are recommended to identify high-risk patients for personalized intervention.},
    year = {2021}
}

